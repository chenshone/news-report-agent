"""ä¸“å®¶å§”å‘˜ä¼š SubAgent

å°è£…ä¸“å®¶åä½œæµç¨‹ï¼ˆé˜¶æ®µ1ç”±å¤–éƒ¨æä¾›ï¼‰ï¼š
1. ç‹¬ç«‹åˆ†æ - å„ä¸“å®¶è¾“å‡ºå·²é¢„å…ˆæä¾›
2. äº¤å‰è¯„å®¡ - ä¸“å®¶äº’è¯„
3. å…±è¯†è®¨è®º - å¤„ç†åˆ†æ­§
4. ä¸»ç®¡ç»¼åˆ - æœ€ç»ˆè£å†³
"""

import asyncio
import json
import re
from typing import Any, Dict, List

from deepagents.middleware.subagents import CompiledSubAgent
from langchain_core.messages import AIMessage
from langchain_core.runnables import RunnableConfig, RunnableLambda

from ...config import AppConfig, create_chat_model
from ...prompts.experts import (
    SUMMARIZER_PROMPT,
    FACT_CHECKER_PROMPT,
    RESEARCHER_PROMPT,
    IMPACT_ASSESSOR_PROMPT,
    EXPERT_SUPERVISOR_PROMPT,
)
from ..council import CROSS_REVIEW_MATRIX, EXPERT_DESCRIPTIONS, generate_cross_review_prompt


# ä¸“å®¶ç³»ç»Ÿæç¤ºè¯ï¼ˆå¤ç”¨ experts.py ä¸­çš„åŸå§‹ promptï¼Œé¿å…å¾ªç¯å¯¼å…¥ï¼‰
_EXPERT_PROMPTS = {
    "summarizer": SUMMARIZER_PROMPT,
    "fact_checker": FACT_CHECKER_PROMPT,
    "researcher": RESEARCHER_PROMPT,
    "impact_assessor": IMPACT_ASSESSOR_PROMPT,
    "expert_supervisor": EXPERT_SUPERVISOR_PROMPT,
}

_EXPECTED_EXPERTS = ("summarizer", "fact_checker", "researcher", "impact_assessor")


def _parse_json_payload(raw: str) -> Dict[str, Any] | None:
    candidates: list[str] = []
    stripped = raw.strip()
    if stripped.startswith("{") and stripped.endswith("}"):
        candidates.append(stripped)

    for match in re.finditer(r"```(?:json)?\n(.*?)```", raw, re.S):
        candidates.append(match.group(1).strip())

    for candidate in candidates:
        try:
            payload = json.loads(candidate)
        except json.JSONDecodeError:
            continue
        if isinstance(payload, dict):
            return payload
    return None


def _extract_expert_payload(raw: str) -> tuple[str, str, Dict[str, str]] | None:
    payload = _parse_json_payload(raw)
    if not payload:
        return None

    expert_outputs = payload.get("expert_outputs")
    if expert_outputs is None:
        expert_outputs = {
            key: payload.get(key)
            for key in _EXPECTED_EXPERTS
            if payload.get(key)
        }

    if not isinstance(expert_outputs, dict) or not expert_outputs:
        return None

    normalized_outputs = {
        key: str(value)
        for key, value in expert_outputs.items()
        if value is not None
    }

    if not normalized_outputs:
        return None

    task = payload.get("task") or payload.get("analysis_task") or "æ‰§è¡Œä¸“å®¶å§”å‘˜ä¼šåˆ†æ"
    context = payload.get("context") or payload.get("news_pack") or payload.get("input") or ""
    return task, context, normalized_outputs


class ExpertCouncilRunner:
    """
    ä¸“å®¶å§”å‘˜ä¼šæ‰§è¡Œå™¨
    
    å°è£…ä¸“å®¶è¯„å®¡ä¸è£å†³æµç¨‹çš„æ‰§è¡Œé€»è¾‘ï¼ˆç‹¬ç«‹åˆ†æç”±å¤–éƒ¨æä¾›ï¼‰ã€‚
    """
    
    def __init__(self, config: AppConfig):
        """åˆå§‹åŒ–æ‰§è¡Œå™¨"""
        self.config = config
        
        # åˆ›å»ºå„ä¸“å®¶çš„æ¨¡å‹å®ä¾‹
        self.expert_models = {
            "summarizer": create_chat_model(config.model_for_role("summarizer"), config),
            "fact_checker": create_chat_model(config.model_for_role("fact_checker"), config),
            "researcher": create_chat_model(config.model_for_role("researcher"), config),
            "impact_assessor": create_chat_model(config.model_for_role("impact_assessor"), config),
            "expert_supervisor": create_chat_model(config.model_for_role("master"), config),
        }
    
    async def run_council(
        self,
        task: str,
        context: str,
        expert_outputs: Dict[str, str],
    ) -> str:
        """æ‰§è¡Œä¸“å®¶å§”å‘˜ä¼šæµç¨‹ï¼ˆé˜¶æ®µ1è¾“å‡ºç”±å¤–éƒ¨æä¾›ï¼‰"""
        if not expert_outputs:
            return "æœªæä¾›ä¸“å®¶è¾“å‡ºï¼Œæ— æ³•è¿›è¡Œäº¤å‰è¯„å®¡ã€‚"

        report_parts = []
        report_parts.append("# ğŸ­ ä¸“å®¶å§”å‘˜ä¼šåˆ†ææŠ¥å‘Š\n")
        report_parts.append(f"**åˆ†æä»»åŠ¡**: {task}\n")
        
        # é˜¶æ®µ 1: ç‹¬ç«‹åˆ†æï¼ˆå·²æä¾›ï¼‰
        report_parts.append("\n---\n## é˜¶æ®µ 1: ç‹¬ç«‹åˆ†æï¼ˆå·²æä¾›ï¼‰\n")
        missing_experts = [
            expert for expert in _EXPECTED_EXPERTS if expert not in expert_outputs
        ]
        if missing_experts:
            report_parts.append(f"âš ï¸ ç¼ºå°‘ä¸“å®¶è¾“å‡º: {', '.join(missing_experts)}\n")

        for expert in _EXPECTED_EXPERTS:
            if expert not in expert_outputs:
                continue
            output = expert_outputs[expert]
            preview = output[:500] + "..." if len(output) > 500 else output
            report_parts.append(f"\n### {expert}\n{preview}\n")
        
        # é˜¶æ®µ 2: äº¤å‰è¯„å®¡
        report_parts.append("\n---\n## é˜¶æ®µ 2: äº¤å‰è¯„å®¡\n")
        reviews, grade_summary = await self._stage2_cross_review(expert_outputs, context)
        
        report_parts.append("\n### è¯„å®¡ç­‰çº§æ±‡æ€»\n")
        for reviewee, grades in grade_summary.items():
            avg_grade = self._calculate_average_grade(grades)
            report_parts.append(f"- **{reviewee}**: {avg_grade} (æ¥è‡ª {len(grades)} ä½è¯„å®¡)\n")
        
        # è¯†åˆ«åˆ†æ­§
        conflicts = self._identify_conflicts(reviews)
        
        # é˜¶æ®µ 3: å…±è¯†è®¨è®º
        discussion_results = ""
        if conflicts:
            report_parts.append(f"\n---\n## é˜¶æ®µ 3: å…±è¯†è®¨è®º\n")
            report_parts.append(f"å‘ç° {len(conflicts)} ä¸ªéœ€è¦è®¨è®ºçš„åˆ†æ­§ç‚¹\n")
            discussion_results = await self._stage3_consensus_discussion(
                conflicts, expert_outputs, context
            )
            report_parts.append(discussion_results)
        else:
            report_parts.append("\n---\n## é˜¶æ®µ 3: å…±è¯†è®¨è®º\n")
            report_parts.append("âœ… ä¸“å®¶æ„è§åŸºæœ¬ä¸€è‡´ï¼Œæ— éœ€é¢å¤–è®¨è®º\n")
        
        # é˜¶æ®µ 4: ä¸»ç®¡ç»¼åˆè£å†³
        report_parts.append("\n---\n## é˜¶æ®µ 4: ä¸»ç®¡ç»¼åˆè£å†³\n")
        final_synthesis = await self._stage4_chairman_synthesis(
            task, expert_outputs, reviews, grade_summary, conflicts, discussion_results
        )
        report_parts.append(final_synthesis)
        
        return "\n".join(report_parts)
    
    async def _stage2_cross_review(
        self, expert_outputs: Dict[str, str], context: str
    ) -> tuple[List[Dict], Dict[str, List[str]]]:
        """é˜¶æ®µ2: äº¤å‰è¯„å®¡"""
        reviews = []
        grade_summary: Dict[str, List[str]] = {}
        
        async def do_review(reviewer: str, reviewee: str, focus: str) -> Dict:
            model = self.expert_models[reviewer]
            
            prompt = generate_cross_review_prompt(
                reviewer=reviewer,
                reviewee=reviewee,
                reviewee_output=expert_outputs.get(reviewee, ""),
                original_context=context[:1000],
                review_focus=focus,
            )
            
            messages = [
                {"role": "system", "content": EXPERT_DESCRIPTIONS.get(reviewer, "")},
                {"role": "user", "content": prompt}
            ]
            
            try:
                response = await model.ainvoke(messages)
                grade = self._extract_grade(response.content)
                return {
                    "reviewer": reviewer,
                    "reviewee": reviewee,
                    "grade": grade,
                    "content": response.content,
                }
            except Exception as e:
                return {
                    "reviewer": reviewer,
                    "reviewee": reviewee,
                    "grade": "C",
                    "content": f"è¯„å®¡å¤±è´¥: {str(e)}",
                }
        
        # æ”¶é›†æ‰€æœ‰è¯„å®¡ä»»åŠ¡
        review_tasks = []
        for reviewee, reviewer_configs in CROSS_REVIEW_MATRIX.items():
            if reviewee not in expert_outputs:
                continue
            for config in reviewer_configs:
                reviewer = config["reviewer"]
                if reviewer in expert_outputs:
                    review_tasks.append(
                        do_review(reviewer, reviewee, config["focus"])
                    )
        
        # å¹¶è¡Œæ‰§è¡Œ
        results = await asyncio.gather(*review_tasks)
        
        for result in results:
            reviews.append(result)
            reviewee = result["reviewee"]
            if reviewee not in grade_summary:
                grade_summary[reviewee] = []
            grade_summary[reviewee].append(result["grade"])
        
        return reviews, grade_summary
    
    def _identify_conflicts(self, reviews: List[Dict]) -> List[Dict]:
        """è¯†åˆ«éœ€è¦è®¨è®ºçš„åˆ†æ­§ç‚¹"""
        conflicts = []
        for review in reviews:
            grade = review.get("grade", "B")
            if grade in ("C", "D"):
                conflicts.append({
                    "topic": f"{review['reviewer']} å¯¹ {review['reviewee']} çš„è¯„å®¡",
                    "grade": grade,
                    "reviewer": review["reviewer"],
                    "reviewee": review["reviewee"],
                    "content": review.get("content", "")[:300],
                })
        return conflicts
    
    async def _stage3_consensus_discussion(
        self,
        conflicts: List[Dict],
        expert_outputs: Dict[str, str],
        context: str,
    ) -> str:
        """é˜¶æ®µ3: å…±è¯†è®¨è®º"""
        if not conflicts:
            return "æ— éœ€è®¨è®º"
        
        discussions = []
        for conflict in conflicts[:3]:  # æœ€å¤šè®¨è®º 3 ä¸ªåˆ†æ­§
            reviewer = conflict["reviewer"]
            reviewee = conflict["reviewee"]
            
            model = self.expert_models.get(reviewee)
            if not model:
                continue
            
            prompt = f"""ä½ æ˜¯ {reviewee}ï¼Œä½ çš„åˆ†æè¢« {reviewer} è¯„ä¸º {conflict['grade']} çº§ã€‚

{reviewer} çš„è¯„å®¡æ„è§:
{conflict['content']}

è¯·é’ˆå¯¹è¿™äº›æ„è§è¿›è¡Œå›åº”ï¼ˆ200å­—å†…ï¼‰ã€‚
"""
            
            try:
                messages = [{"role": "user", "content": prompt}]
                response = await model.ainvoke(messages)
                discussions.append(f"\n### åˆ†æ­§: {conflict['topic']}\n")
                discussions.append(f"**è¯„å®¡ç­‰çº§**: {conflict['grade']}\n")
                discussions.append(f"**{reviewee} çš„å›åº”**:\n{response.content}\n")
            except Exception as e:
                discussions.append(f"\n### åˆ†æ­§: {conflict['topic']}\n")
                discussions.append(f"è®¨è®ºå¤±è´¥: {str(e)}\n")
        
        return "\n".join(discussions)
    
    async def _stage4_chairman_synthesis(
        self,
        task: str,
        expert_outputs: Dict[str, str],
        reviews: List[Dict],
        grade_summary: Dict[str, List[str]],
        conflicts: List[Dict],
        discussion_results: str,
    ) -> str:
        """é˜¶æ®µ4: ä¸»ç®¡ç»¼åˆè£å†³"""
        model = self.expert_models["expert_supervisor"]
        
        # æ ¼å¼åŒ–è¾“å…¥
        expert_text = "\n\n".join([
            f"### {name}\n{output[:800]}..." if len(output) > 800 else f"### {name}\n{output}"
            for name, output in expert_outputs.items()
        ])
        
        review_text = "\n".join([
            f"- {reviewee}: å¹³å‡ç­‰çº§ {self._calculate_average_grade(grades)}"
            for reviewee, grades in grade_summary.items()
        ])
        
        conflict_text = "\n".join([
            f"- {c['topic']}: ç­‰çº§ {c['grade']}"
            for c in conflicts
        ]) if conflicts else "æ— æ˜æ˜¾åˆ†æ­§"
        
        prompt = f"""ä½ æ˜¯ä¸“å®¶å§”å‘˜ä¼šä¸»å¸­ï¼Œéœ€è¦ç»¼åˆæ‰€æœ‰ä¸“å®¶çš„åˆ†æåšæœ€ç»ˆè£å†³ã€‚

## åŸå§‹ä»»åŠ¡
{task}

## å„ä¸“å®¶ç‹¬ç«‹åˆ†æ
{expert_text}

## äº¤å‰è¯„å®¡ç»“æœ
{review_text}

## åˆ†æ­§ç‚¹
{conflict_text}

## è®¨è®ºç»“æœ
{discussion_results if discussion_results else "ä¸“å®¶æ„è§ä¸€è‡´ï¼Œæœªè¿›è¡Œè®¨è®º"}

---

è¯·ç”Ÿæˆæœ€ç»ˆçš„ç»¼åˆè£å†³æŠ¥å‘Šï¼Œä½¿ç”¨ Markdown æ ¼å¼ã€‚
"""
        
        try:
            messages = [
                {"role": "system", "content": _EXPERT_PROMPTS["expert_supervisor"]},
                {"role": "user", "content": prompt}
            ]
            response = await model.ainvoke(messages)
            return response.content
        except Exception as e:
            return f"ä¸»ç®¡ç»¼åˆå¤±è´¥: {str(e)}"
    
    def _extract_grade(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–è¯„å®¡ç­‰çº§"""
        import re
        
        try:
            json_match = re.search(r'"overall_grade"\s*:\s*"([ABCD])"', text, re.IGNORECASE)
            if json_match:
                return json_match.group(1).upper()
        except Exception:
            pass
        
        grade_match = re.search(r'ç­‰çº§[ï¼š:]\s*([ABCD])', text, re.IGNORECASE)
        if grade_match:
            return grade_match.group(1).upper()
        
        return "B"
    
    def _calculate_average_grade(self, grades: List[str]) -> str:
        """è®¡ç®—å¹³å‡ç­‰çº§"""
        if not grades:
            return "B"
        
        grade_values = {"A": 4, "B": 3, "C": 2, "D": 1}
        avg = sum(grade_values.get(g, 3) for g in grades) / len(grades)
        
        if avg >= 3.5:
            return "A"
        elif avg >= 2.5:
            return "B"
        elif avg >= 1.5:
            return "C"
        else:
            return "D"


def create_council(config: AppConfig) -> CompiledSubAgent:
    """
    åˆ›å»ºä¸“å®¶å§”å‘˜ä¼š SubAgent
    
    Args:
        config: åº”ç”¨é…ç½®
        
    Returns:
        é…ç½®å¥½çš„ CompiledSubAgent
    """
    runner = ExpertCouncilRunner(config)
    
    def invoke_fn(state: dict, config_: RunnableConfig | None = None) -> dict:
        """åŒæ­¥è°ƒç”¨"""
        messages = state.get("messages", [])
        if not messages:
            return {"messages": [AIMessage(content="æœªæä¾›åˆ†æä»»åŠ¡")]}
        
        expert_outputs = state.get("expert_outputs")
        task = state.get("task") or state.get("analysis_task") or "æ‰§è¡Œä¸“å®¶å§”å‘˜ä¼šåˆ†æ"
        context = state.get("context") or state.get("news_pack") or ""

        if isinstance(expert_outputs, dict):
            expert_outputs = {
                key: str(value)
                for key, value in expert_outputs.items()
                if value is not None
            }
        else:
            expert_outputs = None

        if not expert_outputs:
            last_message = messages[-1]
            task_content = last_message.content if hasattr(last_message, 'content') else str(last_message)
            payload = _extract_expert_payload(task_content)
            if not payload:
                missing_hint = "ã€".join(_EXPECTED_EXPERTS)
                return {
                    "messages": [
                        *messages,
                        AIMessage(
                            content=(
                                "æœªæä¾›ä¸“å®¶è¾“å‡ºï¼Œæ— æ³•è¿›è¡Œäº¤å‰è¯„å®¡ã€‚è¯·ä¼ å…¥ JSONï¼ŒåŒ…å« task/context "
                                f"ä»¥åŠ expert_outputsï¼ˆ{missing_hint}ï¼‰ã€‚"
                            )
                        ),
                    ]
                }

            task, context, expert_outputs = payload
        
        try:
            result = asyncio.run(runner.run_council(
                task=task,
                context=context,
                expert_outputs=expert_outputs,
            ))
        except Exception as e:
            result = f"ä¸“å®¶å§”å‘˜ä¼šæ‰§è¡Œå¤±è´¥: {str(e)}"
        
        return {
            "messages": [
                *messages,
                AIMessage(content=result)
            ]
        }
    
    async def ainvoke_fn(state: dict, config_: RunnableConfig | None = None) -> dict:
        """å¼‚æ­¥è°ƒç”¨"""
        messages = state.get("messages", [])
        if not messages:
            return {"messages": [AIMessage(content="æœªæä¾›åˆ†æä»»åŠ¡")]}
        
        expert_outputs = state.get("expert_outputs")
        task = state.get("task") or state.get("analysis_task") or "æ‰§è¡Œä¸“å®¶å§”å‘˜ä¼šåˆ†æ"
        context = state.get("context") or state.get("news_pack") or ""

        if isinstance(expert_outputs, dict):
            expert_outputs = {
                key: str(value)
                for key, value in expert_outputs.items()
                if value is not None
            }
        else:
            expert_outputs = None

        if not expert_outputs:
            last_message = messages[-1]
            task_content = last_message.content if hasattr(last_message, 'content') else str(last_message)
            payload = _extract_expert_payload(task_content)
            if not payload:
                missing_hint = "ã€".join(_EXPECTED_EXPERTS)
                return {
                    "messages": [
                        *messages,
                        AIMessage(
                            content=(
                                "æœªæä¾›ä¸“å®¶è¾“å‡ºï¼Œæ— æ³•è¿›è¡Œäº¤å‰è¯„å®¡ã€‚è¯·ä¼ å…¥ JSONï¼ŒåŒ…å« task/context "
                                f"ä»¥åŠ expert_outputsï¼ˆ{missing_hint}ï¼‰ã€‚"
                            )
                        ),
                    ]
                }

            task, context, expert_outputs = payload
        
        try:
            result = await runner.run_council(
                task=task,
                context=context,
                expert_outputs=expert_outputs,
            )
        except Exception as e:
            result = f"ä¸“å®¶å§”å‘˜ä¼šæ‰§è¡Œå¤±è´¥: {str(e)}"
        
        return {
            "messages": [
                *messages,
                AIMessage(content=result)
            ]
        }
    
    runnable = RunnableLambda(invoke_fn, afunc=ainvoke_fn)
    
    return CompiledSubAgent(
        name="expert_council",
        description=(
            "åŸºäºå·²æœ‰ä¸“å®¶è¾“å‡ºæ‰§è¡Œäº¤å‰è¯„å®¡â†’å…±è¯†è®¨è®ºâ†’ä¸»ç®¡ç»¼åˆã€‚"
            "è°ƒç”¨å‰éœ€æä¾› summarizer/fact_checker/researcher/impact_assessor è¾“å‡ºã€‚"
        ),
        runnable=runnable,
    )


__all__ = ["create_council", "ExpertCouncilRunner"]
