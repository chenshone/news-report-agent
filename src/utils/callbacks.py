"""LangChain å›è°ƒå¤„ç†å™¨ï¼Œç”¨äºæ˜¾ç¤º Agent æ‰§è¡Œè¿‡ç¨‹"""

from __future__ import annotations

from typing import Any, Dict, List, Optional, Union
from uuid import UUID

from langchain_core.callbacks.base import BaseCallbackHandler
from langchain_core.messages import BaseMessage
from langchain_core.outputs import LLMResult

from .logger import logger


class AgentProgressCallback(BaseCallbackHandler):
    """
    Agent æ‰§è¡Œè¿›åº¦å›è°ƒå¤„ç†å™¨ã€‚
    
    æ˜¾ç¤º LLM è°ƒç”¨ã€å·¥å…·è°ƒç”¨ã€Agent æ‰§è¡Œç­‰å…³é”®æ­¥éª¤çš„æ—¥å¿—ã€‚
    """
    
    def __init__(self, verbose: bool = True):
        """
        åˆå§‹åŒ–å›è°ƒå¤„ç†å™¨ã€‚
        
        Args:
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        """
        super().__init__()
        self.verbose = verbose
        self._step_count = 0
        self._current_agent = "master"
    
    def on_llm_start(
        self,
        serialized: Dict[str, Any],
        prompts: List[str],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        tags: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> Any:
        """LLM å¼€å§‹è°ƒç”¨æ—¶è§¦å‘"""
        self._step_count += 1
        # å®‰å…¨è·å–æ¨¡å‹åç§°
        model_name = "unknown"
        if serialized:
            model_name = serialized.get("kwargs", {}).get("model_name") or \
                         serialized.get("kwargs", {}).get("model") or \
                         serialized.get("name", "unknown")
        logger.info(f"ğŸ¤– [æ­¥éª¤ {self._step_count}] æ­£åœ¨è°ƒç”¨ LLM: {model_name}")
        if self.verbose and prompts:
            # åªæ˜¾ç¤ºå‰ 200 å­—ç¬¦
            prompt_preview = prompts[0][:200] + "..." if len(prompts[0]) > 200 else prompts[0]
            logger.debug(f"   æç¤ºè¯é¢„è§ˆ: {prompt_preview}")
    
    def on_llm_end(
        self,
        response: LLMResult,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        """LLM è°ƒç”¨å®Œæˆæ—¶è§¦å‘"""
        logger.info(f"âœ… [æ­¥éª¤ {self._step_count}] LLM è°ƒç”¨å®Œæˆ")
        if self.verbose and response.generations:
            # æ˜¾ç¤ºç”Ÿæˆçš„å†…å®¹é¢„è§ˆ
            for gen in response.generations[0]:
                content = gen.text[:300] + "..." if len(gen.text) > 300 else gen.text
                logger.debug(f"   å“åº”é¢„è§ˆ: {content}")
    
    def on_llm_error(
        self,
        error: Union[Exception, KeyboardInterrupt],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        """LLM è°ƒç”¨å‡ºé”™æ—¶è§¦å‘"""
        logger.error(f"âŒ [æ­¥éª¤ {self._step_count}] LLM é”™è¯¯: {error}")
    
    def on_chain_start(
        self,
        serialized: Optional[Dict[str, Any]],
        inputs: Dict[str, Any],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        tags: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> Any:
        """Chain å¼€å§‹æ‰§è¡Œæ—¶è§¦å‘"""
        if not serialized:
            return  # è·³è¿‡ç©ºçš„ serialized
        chain_name = serialized.get("name") or "unknown"
        if isinstance(serialized.get("id"), list) and serialized["id"]:
            chain_name = chain_name or serialized["id"][-1]
        if chain_name and chain_name not in ("RunnableSequence", "unknown"):
            logger.info(f"ğŸ”— å¼€å§‹æ‰§è¡Œé“¾: {chain_name}")
    
    def on_chain_end(
        self,
        outputs: Dict[str, Any],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        """Chain æ‰§è¡Œå®Œæˆæ—¶è§¦å‘"""
        pass  # é¿å…å¤ªå¤šæ—¥å¿—
    
    def on_chain_error(
        self,
        error: Union[Exception, KeyboardInterrupt],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        """Chain æ‰§è¡Œå‡ºé”™æ—¶è§¦å‘"""
        logger.error(f"âŒ Chain é”™è¯¯: {error}")
    
    def on_tool_start(
        self,
        serialized: Optional[Dict[str, Any]],
        input_str: str,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        tags: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> Any:
        """å·¥å…·å¼€å§‹è°ƒç”¨æ—¶è§¦å‘"""
        tool_name = serialized.get("name", "unknown") if serialized else "unknown"
        logger.info(f"ğŸ”§ æ­£åœ¨è°ƒç”¨å·¥å…·: {tool_name}")
        if self.verbose and input_str:
            input_preview = input_str[:200] + "..." if len(input_str) > 200 else input_str
            logger.debug(f"   å·¥å…·è¾“å…¥: {input_preview}")
    
    def on_tool_end(
        self,
        output: str,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        """å·¥å…·è°ƒç”¨å®Œæˆæ—¶è§¦å‘"""
        logger.info(f"âœ… å·¥å…·è°ƒç”¨å®Œæˆ")
        if self.verbose:
            output_preview = str(output)[:300] + "..." if len(str(output)) > 300 else str(output)
            logger.debug(f"   å·¥å…·è¾“å‡º: {output_preview}")
    
    def on_tool_error(
        self,
        error: Union[Exception, KeyboardInterrupt],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        """å·¥å…·è°ƒç”¨å‡ºé”™æ—¶è§¦å‘"""
        logger.error(f"âŒ å·¥å…·é”™è¯¯: {error}")
    
    def on_agent_action(
        self,
        action: Any,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        """Agent æ‰§è¡ŒåŠ¨ä½œæ—¶è§¦å‘"""
        tool_name = getattr(action, "tool", "unknown")
        logger.info(f"ğŸ¯ Agent å†³å®šè°ƒç”¨: {tool_name}")
    
    def on_agent_finish(
        self,
        finish: Any,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        """Agent å®Œæˆæ—¶è§¦å‘"""
        logger.info(f"ğŸ Agent æ‰§è¡Œå®Œæˆ")


class StreamingProgressCallback(BaseCallbackHandler):
    """
    æµå¼è¾“å‡ºå›è°ƒå¤„ç†å™¨ã€‚
    
    å®æ—¶æ˜¾ç¤º LLM ç”Ÿæˆçš„ tokenã€‚
    """
    
    def __init__(self, print_tokens: bool = True):
        super().__init__()
        self.print_tokens = print_tokens
        self._buffer = ""
    
    def on_llm_new_token(
        self,
        token: str,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        """æ¯ä¸ªæ–° token ç”Ÿæˆæ—¶è§¦å‘"""
        if self.print_tokens:
            print(token, end="", flush=True)
            self._buffer += token
    
    def on_llm_end(
        self,
        response: LLMResult,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        """LLM å®Œæˆæ—¶æ¢è¡Œ"""
        if self.print_tokens and self._buffer:
            print()  # æ¢è¡Œ
            self._buffer = ""


def get_default_callbacks(verbose: bool = False, streaming: bool = False) -> List[BaseCallbackHandler]:
    """
    è·å–é»˜è®¤çš„å›è°ƒå¤„ç†å™¨åˆ—è¡¨ã€‚
    
    Args:
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        streaming: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º
        
    Returns:
        å›è°ƒå¤„ç†å™¨åˆ—è¡¨
    """
    callbacks = [AgentProgressCallback(verbose=verbose)]
    if streaming:
        callbacks.append(StreamingProgressCallback())
    return callbacks


__all__ = [
    "AgentProgressCallback",
    "StreamingProgressCallback", 
    "get_default_callbacks",
]

